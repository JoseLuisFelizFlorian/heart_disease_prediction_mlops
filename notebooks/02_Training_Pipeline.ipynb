{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPCwoi1KHz2HDEoj2Sobibi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Proyecto Heart Disease Prediction\n","\n","## Pipeline de Entrenamiento, Optimización y Serialización\n","\n","**Objetivo**\n","Transformar los datos limpios (`interim`) en artefactos de Machine Learning listos para producción. Este notebook ejecuta un flujo de trabajo completo que incluye ingeniería de características, imputación, escalado, búsqueda de hiperparámetros (GridSearch) y persistencia de múltiples modelos.\n","\n","**Metodología:**\n","1.  **Ingeniería de Features:** Transformación de variables categóricas (One-Hot Encoding).\n","2.  **Preprocesamiento Robusto:** Creación y guardado de `Imputer` y `Scaler` para garantizar consistencia en inferencia.\n","3.  **Hyperparameter Tuning:** Optimización de 4 algoritmos clave usando Validación Cruzada (5-Fold CV):\n","    * *Logistic Regression*\n","    * *Support Vector Machine (SVM)*\n","    * *Decision Tree*\n","    * *Random Forest*\n","4.  **Persistencia MLOps:** Serialización de todos los modelos y generación de un archivo `metrics.json` para el Dashboard de la App.\n","\n","---\n","* **Autor:** [Feliz Florian Jose Luis]\n","* **Fecha:** [12/12/2025]\n","* **Input:** `data/02_interim/heart_disease_prediction_cleaned.csv`\n","* **Output:** Modelos en `data/05_models` y Artefactos en `artefacts/`.\n","---"],"metadata":{"id":"mpwKIaopkZYm"}},{"cell_type":"code","source":["# --- Librerías estándar ---\n","import pandas as pd\n","import numpy as np\n","import pickle\n","import json\n","import os\n","from google.colab import drive\n","\n","# --- Librerías de visualización ---\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","# --- Scikit-Learn ---\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, classification_report\n","\n","# Montaje de Unidad (Persistencia en Google Drive)\n","drive.mount('/content/drive')\n","\n","# --- DEFINICIÓN DE RUTAS (CONSTANTES) ---\n","\n","# Ruta Base (Ancla del Proyecto)\n","PROJECT_DIR = \"/content/drive/MyDrive/Colab Notebooks/heart_disease_prediction_mlops\"\n","\n","# Inputs (Datos Limpios del EDA)\n","INTERIM_DATA_PATH = os.path.join(PROJECT_DIR, \"data\", \"02_interim\", \"heart_disease_prediction_cleaned.csv\")\n","\n","# Outputs (Destinos de guardado)\n","MODELS_DIR = os.path.join(PROJECT_DIR, \"data\", \"05_models\")\n","ARTEFACTS_DIR = os.path.join(PROJECT_DIR, \"artefacts\")\n","REPORTS_DIR = os.path.join(PROJECT_DIR, \"data\", \"06_reporting\")\n","\n","# --- VALIDACIÓN DE DIRECTORIOS ---\n","\n","# Creamos directorios si no existen\n","os.makedirs(MODELS_DIR, exist_ok=True)\n","os.makedirs(ARTEFACTS_DIR, exist_ok=True)\n","os.makedirs(REPORTS_DIR, exist_ok=True)\n","print(\"\\n\")\n","print(f\"Entorno Configurado.\\n\")\n","print(f\"Input Data: {INTERIM_DATA_PATH}\\n\")\n","print(f\"Directorio de Modelos: {MODELS_DIR}\\n\")\n","print(f\"Directorio de Artefactos: {ARTEFACTS_DIR}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4X1GdXYlkUH0","executionInfo":{"status":"ok","timestamp":1765567921810,"user_tz":-60,"elapsed":4112,"user":{"displayName":"Feliz Florian Jose Luis","userId":"10540021710746206030"}},"outputId":"ffe28e2d-f886-476c-d14f-f142d753e3c9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","\n","Entorno Configurado.\n","\n","Input Data: /content/drive/MyDrive/Colab Notebooks/heart_disease_prediction_mlops/data/02_interim/heart_disease_prediction_cleaned.csv\n","\n","Directorio de Modelos: /content/drive/MyDrive/Colab Notebooks/heart_disease_prediction_mlops/data/05_models\n","\n","Directorio de Artefactos: /content/drive/MyDrive/Colab Notebooks/heart_disease_prediction_mlops/artefacts\n","\n"]}]},{"cell_type":"markdown","source":["## 1. Pipeline de Datos y Generación de Artefactos\n","\n","Transformación de variables categóricas y normalización numérica. El objetivo es preparar los datos y, simultáneamente, exportar las reglas de transformación para el despliegue.\n","\n","**Puntos Críticos de MLOps:**\n","1.  **Validación Futura:** Guardamos `features_names.pkl` para garantizar que, cuando despleguemos la aplicación, podamos rechazar archivos o datos que no tengan las columnas correctas.\n","2.  **Reproducibilidad:** Exportamos el `Imputer` y el `Scaler`. Así, cuando la App reciba un paciente nuevo en el futuro, aplicará la misma mediana y la misma escala que usamos aquí, garantizando predicciones coherentes."],"metadata":{"id":"l07PwkBVePif"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFXbZpKmc1i_","executionInfo":{"status":"ok","timestamp":1765567923623,"user_tz":-60,"elapsed":1801,"user":{"displayName":"Feliz Florian Jose Luis","userId":"10540021710746206030"}},"outputId":"e758822d-ca71-403a-b09e-096be9c4caf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Datos cargados: (918, 12)\n","\n","Lista de features guardada (15 variables).\n","\n","Preprocesamiento completado y artefactos guardados en 'artefacts/'.\n","\n"]}],"source":["# Carga de Datos\n","try:\n","    print(\"\\n\")\n","    df = pd.read_csv(INTERIM_DATA_PATH)\n","    print(f\"Datos cargados: {df.shape}\\n\")\n","except FileNotFoundError:\n","    print(\"ERROR CRÍTICO: No se encuentra el archivo interim. Ejecuta el Notebook 01_EDA_Analysis primero.\\n\")\n","\n","# One-Hot Encoding (Transformación de Texto a Números)\n","df_encoded = pd.get_dummies(df, drop_first=True)\n","\n","# Separación Features (X) y Target (y)\n","X = df_encoded.drop(columns=['HeartDisease'])\n","y = df_encoded['HeartDisease']\n","\n","# --- MLOps: GUARDAR NOMBRES DE FEATURES ---\n","\n","feature_names = list(X.columns)\n","with open(os.path.join(ARTEFACTS_DIR, \"features_names.pkl\"), \"wb\") as f:\n","    pickle.dump(feature_names, f)\n","print(f\"Lista de features guardada ({len(feature_names)} variables).\\n\")\n","\n","# División Train/Test (Estratificada)\n","# Mantenemos la proporción de enfermos/sanos igual en ambos sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","# Imputación (Manejo de Nulos)\n","# Usamos la Mediana para rellenar los huecos de Cholesterol/RestingBP generados en la limpieza\n","imputer = SimpleImputer(strategy='median')\n","X_train_imputed = imputer.fit_transform(X_train)\n","X_test_imputed = imputer.transform(X_test)\n","\n","# --- MLOps: GUARDAR IMPUTER ---\n","\n","with open(os.path.join(ARTEFACTS_DIR, \"imputer.pkl\"), \"wb\") as f:\n","    pickle.dump(imputer, f)\n","\n","# Escalado (Estandarización)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train_imputed)\n","X_test_scaled = scaler.transform(X_test_imputed)\n","\n","# --- MLOps: GUARDAR SCALER ---\n","\n","with open(os.path.join(ARTEFACTS_DIR, \"scaler.pkl\"), \"wb\") as f:\n","    pickle.dump(scaler, f)\n","\n","print(\"Preprocesamiento completado y artefactos guardados en 'artefacts/'.\\n\")"]},{"cell_type":"markdown","source":["## 2. Entrenamiento y Optimización de Hiperparámetros\n","\n","Utilizamos **`GridSearchCV`** para encontrar la mejor configuración para cada algoritmo.\n","* **Estrategia:** Probamos múltiples combinaciones (Solvers, Kernels, Profundidades) usando Validación Cruzada de 5 pliegues (5-Fold CV).\n","* **Métrica de Selección:** Optimizamos buscando el mejor **Recall**, ya que en medicina es prioritario detectar a todos los enfermos."],"metadata":{"id":"bNozO3rrgA5u"}},{"cell_type":"code","source":["# Diccionario para almacenar los mejores modelos encontrados\n","best_models = {}\n","\n","print(\"\\n INICIANDO OPTIMIZACIÓN DE HIPERPARÁMETROS (GridSearch)...\")\n","\n","# --- REGRESIÓN LOGÍSTICA ---\n","print(\"\\n Optimizando Logistic Regression...\")\n","param_grid_lr = {\n","    'solver': ['liblinear', 'lbfgs'],\n","    'C': [0.01, 0.1, 1, 10, 100]\n","}\n","grid_lr = GridSearchCV(LogisticRegression(random_state=42, max_iter=1000), param_grid_lr, cv=5, scoring='recall')\n","grid_lr.fit(X_train_scaled, y_train)\n","best_models[\"logistic_regression\"] = grid_lr.best_estimator_\n","print(f\"   -> Mejores Params: {grid_lr.best_params_}\")\n","\n","# --- SUPPORT VECTOR MACHINE (SVM) ---\n","print(\"\\n Optimizando SVM...\")\n","param_grid_svm = {\n","    'kernel': ['linear', 'rbf'],\n","    'C': [0.1, 1, 10],\n","    'gamma': ['scale', 'auto']\n","}\n","# 'probability=True' es vital para que la App muestre la confianza de la predicción\n","grid_svm = GridSearchCV(SVC(probability=True, random_state=42), param_grid_svm, cv=5, scoring='recall')\n","grid_svm.fit(X_train_scaled, y_train)\n","best_models[\"support_vector_machine\"] = grid_svm.best_estimator_\n","print(f\"   -> Mejores Params: {grid_svm.best_params_}\")\n","\n","# --- DECISION TREE ---\n","print(\"\\n Optimizando Decision Tree...\")\n","param_grid_dt = {\n","    'max_depth': [3, 5, 7, 10, None],\n","    'class_weight': ['balanced', None],\n","    'min_samples_split': [2, 5, 10]\n","}\n","grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=5, scoring='recall')\n","grid_dt.fit(X_train_scaled, y_train)\n","best_models[\"decision_tree\"] = grid_dt.best_estimator_\n","print(f\"   -> Mejores Params: {grid_dt.best_params_}\")\n","\n","# --- RANDOM FOREST ---\n","print(\"\\n Optimizando Random Forest...\")\n","param_grid_rf = {\n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [5, 10, None],\n","    'class_weight': ['balanced', None]\n","}\n","grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='recall')\n","grid_rf.fit(X_train_scaled, y_train)\n","best_models[\"random_forest\"] = grid_rf.best_estimator_\n","print(f\"   -> Mejores Params: {grid_rf.best_params_}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GePmpIuJgCKl","executionInfo":{"status":"ok","timestamp":1765567964556,"user_tz":-60,"elapsed":40931,"user":{"displayName":"Feliz Florian Jose Luis","userId":"10540021710746206030"}},"outputId":"e0d9046c-c4c4-4ace-9252-eff550dd3d98"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," INICIANDO OPTIMIZACIÓN DE HIPERPARÁMETROS (GridSearch)...\n","\n"," Optimizando Logistic Regression...\n","   -> Mejores Params: {'C': 0.01, 'solver': 'lbfgs'}\n","\n"," Optimizando SVM...\n","   -> Mejores Params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n","\n"," Optimizando Decision Tree...\n","   -> Mejores Params: {'class_weight': 'balanced', 'max_depth': 3, 'min_samples_split': 2}\n","\n"," Optimizando Random Forest...\n","   -> Mejores Params: {'class_weight': None, 'max_depth': 5, 'n_estimators': 200}\n"]}]},{"cell_type":"markdown","source":["## 3. Evaluación Comparativa y Serialización\n","\n","1.  **Evaluación:** Probamos los modelos optimizados en el **Test Set** (datos nunca vistos). Calculamos *Accuracy*, *Recall* y *F1-Score*.\n","2.  **Generación de Métricas:** Guardamos los resultados en `metrics.json` para alimentar el Dashboard de Streamlit.\n","3.  **Serialización:** Guardamos cada modelo individualmente como `.pkl`."],"metadata":{"id":"RFPG90oxgeH8"}},{"cell_type":"code","source":["# Diccionario maestro para el JSON de métricas\n","final_metrics = {}\n","\n","print(\"\\n EVALUACIÓN FINAL EN TEST SET Y GUARDADO:\")\n","print(\"=\" * 80 +\"\\n\")\n","\n","for name_key, model in best_models.items():\n","    # Predicción\n","    y_pred = model.predict(X_test_scaled)\n","\n","    # Cálculo de Métricas\n","    acc = accuracy_score(y_test, y_pred)\n","    rec = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","\n","    # Almacenamiento en Memoria (JSON Struct)\n","    final_metrics[name_key] = {\n","        \"accuracy\": round(acc, 4),\n","        \"recall\": round(rec, 4),\n","        \"f1_score\": round(f1, 4)\n","    }\n","\n","    print(f\" {name_key.upper():<20} | Recall: {rec:.2%} | F1-Score: {f1:.2%} | Accuracy: {acc:.2%}\")\n","\n","    # Serialización del Modelo (.pkl)\n","    # Nomenclatura: model_nombre_del_algoritmo.pkl\n","    filename = f\"model_{name_key}.pkl\"\n","    path = os.path.join(MODELS_DIR, filename)\n","\n","    with open(path, \"wb\") as f:\n","        pickle.dump(model, f)\n","    print(f\"   Modelo guardado en: {filename}\\n\")\n","\n","print(\"=\" * 80)\n","\n","# Guardado del Archivo de Métricas (JSON)\n","metrics_path = os.path.join(REPORTS_DIR, \"metrics.json\")\n","with open(metrics_path, \"w\") as f:\n","    json.dump(final_metrics, f, indent=4)\n","\n","print(f\"Archivo 'metrics.json' generado en: {REPORTS_DIR}\\n\")\n","print(\"Pipeline finalizado exitosamente. Listos para Streamlit.\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUZv2C3CgFRF","executionInfo":{"status":"ok","timestamp":1765567964648,"user_tz":-60,"elapsed":91,"user":{"displayName":"Feliz Florian Jose Luis","userId":"10540021710746206030"}},"outputId":"27547b94-9237-46e1-cb55-18293176199a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," EVALUACIÓN FINAL EN TEST SET Y GUARDADO:\n","================================================================================\n","\n"," LOGISTIC_REGRESSION  | Recall: 89.22% | F1-Score: 89.66% | Accuracy: 88.59%\n","   Modelo guardado en: model_logistic_regression.pkl\n","\n"," SUPPORT_VECTOR_MACHINE | Recall: 89.22% | F1-Score: 88.35% | Accuracy: 86.96%\n","   Modelo guardado en: model_support_vector_machine.pkl\n","\n"," DECISION_TREE        | Recall: 75.49% | F1-Score: 77.78% | Accuracy: 76.09%\n","   Modelo guardado en: model_decision_tree.pkl\n","\n"," RANDOM_FOREST        | Recall: 87.25% | F1-Score: 86.41% | Accuracy: 84.78%\n","   Modelo guardado en: model_random_forest.pkl\n","\n","================================================================================\n","Archivo 'metrics.json' generado en: /content/drive/MyDrive/Colab Notebooks/heart_disease_prediction_mlops/data/06_reporting\n","\n","Pipeline finalizado exitosamente. Listos para Streamlit.\n","\n"]}]},{"cell_type":"markdown","source":["## 4. Conclusiones y Próximos Pasos\n","\n","El pipeline de entrenamiento ha finalizado con éxito. Se han logrado los siguientes hitos:\n","\n","1.  **Modelado:** Se han entrenado y optimizado 4 algoritmos diferentes, utilizando validación cruzada para evitar el sobreajuste.\n","2.  **Foco Clínico:** La optimización se centró en la métrica **Recall**, priorizando la detección de casos positivos (enfermos).\n","3.  **Persistencia Completa:** Se han exportado todos los componentes necesarios para construir la aplicación web:\n","    * `scaler.pkl` y `imputer.pkl` para preprocesar nuevos datos.\n","    * 4 Modelos `.pkl` (`Logistic Regression`,`Support Vector Machine (SVM)`, `Decision Tree`, `Random Forest`) para predicción flexible.\n","    * `metrics.json` para la visualización comparativa de rendimiento.\n","\n","**Siguiente Fase:** Desarrollo de la Interfaz de Usuario con **Streamlit**."],"metadata":{"id":"eypL3-ZsgjrD"}},{"cell_type":"code","source":[],"metadata":{"id":"3ObkqMyCRDBG","executionInfo":{"status":"ok","timestamp":1765567964657,"user_tz":-60,"elapsed":7,"user":{"displayName":"Feliz Florian Jose Luis","userId":"10540021710746206030"}}},"execution_count":4,"outputs":[]}]}